{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tag import pos_tag\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.classify import accuracy,NaiveBayesClassifier \n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer,WordNetLemmatizer\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import random\n",
    "import string#punctuation\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import spacy\n",
    "#13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    df = pd.read_csv(\"movie-review.csv\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pos(tag):\n",
    "    if tag.startswith('J'):\n",
    "        return 'a'\n",
    "    if tag.startswith('R'):\n",
    "        return 'r'\n",
    "    if tag.startswith('N'):\n",
    "        return 'n'\n",
    "    if tag.startswith('V'):#\n",
    "        return 'v'\n",
    "    else:\n",
    "        return 'n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(words):\n",
    "    wnl=WordNetLemmatizer#kalau gk isa tambahi()\n",
    "    stemmer = PorterStemmer()    \n",
    "    words = [word for word in words if word not in stopwords.words('english')]\n",
    "    words = [word for word in words if word not in string.punctuation]\n",
    "    words = [word for word in words if word.isalpha()]\n",
    "    words = [stemmer.stem(word) for word in words]#stem\n",
    "    tagging = pos_tag(words)\n",
    "    words = [wnl.lemmatize(word,get_pos(tag)) for tag,word in tagging]\n",
    "    \n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model():\n",
    "    #1.Load\n",
    "    df = load_data().sample(3000)\n",
    "    #2.Feature Selection\n",
    "    reviews = [str(review) for review in df['review'].to_list()]#string ->str\n",
    "    sentiments = [str(sentiment) for sentiment in df['sentimentScore'].to_list()]\n",
    "        \n",
    "    #3.Word list\n",
    "    word_list = []\n",
    "    for sentences in reviews:\n",
    "        words = word_tokenize(sentences)\n",
    "        for word in words:\n",
    "            word_list.append(word)\n",
    "            \n",
    "\n",
    "    #4.Preprocessing\n",
    "    word_list = preprocessing(word_list)\n",
    "\n",
    "    # 5Freqdist\n",
    "    fd=FreqDist()\n",
    "    word_features = [word for word,_ in fd.most_common(300)]\n",
    "    \n",
    "    #6compare tujuannya biar dapat sentiment di feature set\n",
    "    labeled_list = list(zip(reviews,sentiments))\n",
    "    features_set=[]\n",
    "    for review, sentiment in labeled_list:\n",
    "        features={}\n",
    "        check_words = word_tokenize(review)\n",
    "        check_words = preprocessing(check_words)\n",
    "        \n",
    "        for word in word_features:\n",
    "            features[word] = word in check_words\n",
    "        features_set.append((features,sentiment))\n",
    "        \n",
    "    #7.splitting\n",
    "    random.shuffle(features_set)\n",
    "    train_count = int(len(features_set) * 0.8)\n",
    "    train_set = features_set[:train_count]\n",
    "    test_set = features_set[train_count:]\n",
    "\n",
    "    #8.train\n",
    "    classifier = NaiveBayesClassifier.train(train_set)\n",
    "    print(f'Accuracy score:{accuracy(classifier,test_set)}')\n",
    "\n",
    "    #9.Write file\n",
    "    file = open(\"model.pickle\",\"wb\")\n",
    "    pickle.dump(classifier,file)#\n",
    "    file.close()\n",
    "    \n",
    "    #10\n",
    "    return classifier\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "review = \"\"\n",
    "category = \"\"\n",
    "classifier = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "try:\n",
    "    file = open(\"model.pickle\", \"rb\")\n",
    "    classifier = pickle.load(file)\n",
    "    file.close()\n",
    "except:\n",
    "    classifier = train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "def menu1():\n",
    "    #1.\n",
    "    global review\n",
    "    global category\n",
    "    global classifier\n",
    "    \n",
    "    #2\n",
    "    while True:    \n",
    "        inputrev = input(\"Input your review(at least contain 5 words):\")\n",
    "        if len(inputrev.split(' '))>=5:\n",
    "            break\n",
    "        else:\n",
    "            print(f'Input must have at least 5 words')\n",
    "    #3\n",
    "    review = inputrev\n",
    "    category = classifier.classify(FreqDist(review))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "def menu2():\n",
    "    global review\n",
    "    #1.validasi\n",
    "    if(review==\"\"):\n",
    "        print(f\"Please input your review first\")\n",
    "        return\n",
    "    \n",
    "    #2.load\n",
    "    df = load_data()\n",
    "    #3.feature selection\n",
    "    reviews = [str(reviewd) for reviewd in df['review'].to_list()]\n",
    "    titles =  [str(title) for title in df['title'].to_list()]\n",
    "    #4tfidf\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    matrix = vectorizer.fit_transform(reviews)\n",
    "    query_matrix = vectorizer.transform([review])\n",
    "    #5cosine_similarity\n",
    "    cosine_similarities = cosine_similarity(query_matrix,matrix).flatten()\n",
    "    # print(cosine_similarities)\n",
    "    #6.ambil index\n",
    "    related_indices_doc = cosine_similarities.argsort()[::-1][:2]\n",
    "    #7.tampilkan\n",
    "    for i,idx in enumerate(related_indices_doc):\n",
    "        print(f'{i+1}: {titles[idx]}')    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "def menu3():\n",
    "    #1.load data\n",
    "    df = load_data().sample(3000)\n",
    "    #2.feature selection\n",
    "    reviews = df['review'].to_string()\n",
    "    # print(reviews)\n",
    "    #3.load model\n",
    "    spacy_nlp= spacy.load(\"en_core_web_sm\")\n",
    "    doc = spacy_nlp(reviews)\n",
    "    \n",
    "    \n",
    "    #4cateries[label].append(text)\n",
    "    categories={}\n",
    "    \n",
    "    for ent in doc.ents:\n",
    "        label = ent.label_\n",
    "        if(label not in('LANGUAGE','LOC')):\n",
    "            continue\n",
    "        if label not in categories:\n",
    "            categories[label]=[]\n",
    "        categories[label].append(ent.text)\n",
    "    \n",
    "    #5display \n",
    "    for label,entities in categories.items():#\n",
    "        print(f'Label:{label},Entities:{entities}')\n",
    "    \n",
    "    if(categories==0):\n",
    "        print(f\"Entities not found\")    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    global review\n",
    "    global category\n",
    "    while True:\n",
    "        print(f'MOVIE RECOMMENDATION APPLICATION BASED ON REVIEWS')\n",
    "        if(review==\"\"):\n",
    "            print(f'YOUR REVIEW : NO REVIEW')\n",
    "            print(f'YOUR REVIEW CATEGORY : NO REVIEW')\n",
    "        else:\n",
    "            print(f'YOUR REVIEW : {review}')\n",
    "            print(f'YOUR REVIEW CATEGORY : {category}')\n",
    "        print(f'1.Write Your Review')\n",
    "        print(f'2.View Movie Recommendation')\n",
    "        print(f'3.View Named Entity Recognition')\n",
    "        print(f'4.Exit')\n",
    "        opt = int(input(\"Input your choice:\"))\n",
    "        if opt == 1:\n",
    "            menu1()\n",
    "        elif opt == 2:\n",
    "            menu2()\n",
    "        elif opt == 3:\n",
    "            menu3()\n",
    "        elif opt == 4:\n",
    "            break\n",
    "        else:\n",
    "            print(f'Please reinput in between 1-4')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MOVIE RECOMMENDATION APPLICATION BASED ON REVIEWS\n",
      "YOUR REVIEW : DEW SDF DFG FFD DF\n",
      "YOUR REVIEW CATEGORY : POSITIVE\n",
      "1.Write Your Review\n",
      "2.View Movie Recommendation\n",
      "3.View Named Entity Recognition\n",
      "4.Exit\n"
     ]
    }
   ],
   "source": [
    "main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
